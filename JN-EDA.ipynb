{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains steps to clean and inspect data before performing analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid.anchored_artists import AnchoredText\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({\n",
    "    'font.size'           : 16.0,\n",
    "    'axes.titlesize'      : 'large',\n",
    "    'axes.labelsize'      : 'medium',\n",
    "    'xtick.labelsize'     : 'small',\n",
    "    'ytick.labelsize'     : 'small',\n",
    "    'legend.fontsize'     : 'small',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "raw = pd.read_csv('data/file.csv', parse_dates=[col])\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the overall shape of the data (rows, columns)\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make changes to copy\n",
    "df = raw.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a subsample if large data is running slowly\n",
    "# df = df.iloc[:5000]\n",
    "df = df.sample(frac=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename specific columns\n",
    "df = df.rename(columns={'old name 1': 'new name’})\n",
    "# Batch rename all columns\n",
    "df.columns = ['']\n",
    "# Clean up formatting for column names if needed\n",
    "df.rename(columns=lambda x: x.strip().replace(\" \", \"_\").lower(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking data types of columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change any data types that are incorrect\n",
    "df.col = df.col.astype(data={col: dtype, ...}, copy=False)\n",
    "# Check data type for all columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "http://pandas.pydata.org/pandas-docs/stable/missing_data.html#cleaning-filling-missing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boolean mask to see NaN values\n",
    "pd.isnull(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking percentage of null values\n",
    "nulls = df.isnull().sum()/float(df.shape[0])\n",
    "nulls.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at any found null values by column\n",
    "null_values = df.loc[df[col].isnull()]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking percentage of null values in each row\n",
    "null_rows = []\n",
    "null_index = []\n",
    "\n",
    "for i in range(5000):\n",
    "    null_index.append(i)\n",
    "    null_rows.append(df.iloc[i,:].isnull().sum()/float(df.shape[1]))\n",
    "    \n",
    "# Largest percent null values in rows\n",
    "max(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with 25% or more null values\n",
    "for col in df:\n",
    "    if df[col].isnull().sum()/float(df.shape[0]) >= 0.25:\n",
    "        df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temp fill numerical null values\n",
    "for col in numerical_vals:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temp fill categorical null values\n",
    "df[col].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ...other filling methods...\n",
    "# method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at any duplicate values\n",
    "dups = df[df.duplicated()]\n",
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate identifiers\n",
    "dup_ids = pd.concat(x for _, x in df.groupby('_') if len(x) > 1).sort_values('_')\n",
    "dup_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove any duplicate identifiers\n",
    "# Pandas will keep the first value, and drop all the following rows\n",
    "df.drop_duplicates('_', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort data to make sure you drop the intended row\n",
    "df.sort_values(['_','_'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = df.columns.values\n",
    "numerical_vals = df.select_dtypes(exclude=['object', 'bool'])                                     \n",
    "categorical_vals = df.select_dtypes(include=['object', 'bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at summary statistics for continous values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for collinearity between variables\n",
    "c = df.corr().round(4).abs()\n",
    "start = int(c.shape[0])\n",
    "c.unstack().sort_values(ascending=False)[start:start+10] # top 5\n",
    "# c.to_csv('../data/correlation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seaborn plots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bar graphs of individual categorical columns\n",
    "for i,col in enumerate(categorical_vals):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(col)\n",
    "    c = sns.countplot(x=df[col], ax=ax);\n",
    "    c.set_xticklabels(c.get_xticklabels(), rotation=45)\n",
    "    plt.savefig('../plots/bargraph_{}'.format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boxplots of individual numerical columns\n",
    "for i,col in enumerate(numerical_vals):\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.violinplot(x=df[col], orient='v', ax=ax)\n",
    "    text = '75th Percentile: {}\\nMedian: {}\\n25th Percentile: {}'.format(np.percentile(df[col], 75),\\\n",
    "            np.median(df[col]),np.percentile(df[col], 25))\n",
    "    at = AnchoredText(text, prop=dict(size=15), frameon=True, loc=1)\n",
    "    ax.add_artist(at)\n",
    "    plt.savefig('../plots/violinplot_{}'.format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stripplot of target (continuous) by all object columns values\n",
    "target = _ # continuous\n",
    "for i,col in enumerate(categorical_vals):\n",
    "    if col != target: \n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        ax = fig.add_subplot(111)\n",
    "        sns.stripplot(x=df[col], y=df[target], orient='v', ax=ax)\n",
    "        plt.savefig('../plots/stripplot_{}'.format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scattermatrix of all numerical columns\n",
    "sns.pairplot(df[numerical_vals])\n",
    "plt.savefig('../plots/scattermatrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas plots...  \n",
    "http://pandas.pydata.org/pandas-docs/stable/visualization.html  \n",
    "df.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter\n",
    "df.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Histogram \n",
    "df[num_col].plot.hist(bins=20)\n",
    "df[cat_col].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Line\n",
    "df[num_col].plot(logx=False, logy=False)\n",
    "df[num_col].plot(x_compat=True, secondary_y=False)\n",
    "df.plot(subplots=True, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bar\n",
    "df[numerical_vals].plot.bar(yerr=errors) # errors (std dev) for error bars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Box\n",
    "color = dict(boxes='DarkGreen', whiskers='DarkOrange', medians='DarkBlue', caps='Gray')\n",
    "df[numerical_vals].plot.box(color=color, sym='r+', vertical=True)\n",
    "\n",
    "df.groupby(cat_col).boxplot()\n",
    "\n",
    "df.boxplot(by='X') # stratified by X\n",
    "df.boxplot(column=['Col1','Col2'], by=['X','Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scatter and scatter matrix\n",
    "df[num_col].plot.scatter(x='', y=df[target], c=color_values, s=size)\n",
    "pd.plotting.scatter_matrix(df[numerical_vals], alpha=0.2, figsize=(6, 6), diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verify that target data is normally distributed\n",
    "df[target].plot.kde\n",
    "# If not, transform with log or sqrt\n",
    "df[target] = np.log(df[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate and groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"col\"].value_counts() # count number of each unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(target).get_group(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-tabulation of feature vs target\n",
    "pd.crosstab(df.col, df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn continuous data into categorical data \n",
    "bin_series = pd.cut(df[col], bins=np.arange(1, 10))\n",
    "bin_series.name = ''\n",
    "pd.concat([df, bin_series], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pivot table\n",
    "print(cols)\n",
    "pd.pivot_table(df, values=col, index=target, columns=col, aggfunc=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(col).mean() \n",
    "# .std() Standard deviation ouses n-1, not N, by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg = df.agg(mean)\n",
    "agg.unstack(level = 'column') # Takes column agg and moves from rows to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map ranked values in list {‘low’:1, ‘medium’:2, ‘high’:3}\n",
    "pd.Series(pd.Categorical(values, categories=['low', 'medium', 'high'], ordered=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for normality, imbalanced classes, outliers, high leverage points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply formatting where appropriate\n",
    "df['Names'] = df.Names.apply(lambda x: x.lower())\n",
    "pd.series.map()\n",
    "df.applymap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Review unique values\n",
    "df[col].unique()\n",
    "df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "df = pd.get_dummies(df.col)\n",
    "df = pd.get_dummies(df, columns=['col1', 'col2'], drop_first=True, dummy_na=True, prefix='dum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Force object coded columns to numerical values\n",
    "df[col] = pd.to_numeric(df.col, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join dataframes, add/remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join by appending rows/columns based on a given axis\n",
    "pd.concat([df1,df2,series], axis=1)\n",
    "# Merge on common columns\n",
    "pd.merge(df1, df2, on=’column’)\n",
    "# Join on common indices\n",
    "joined = df1.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an empty column \n",
    "df['empty col'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append a new row\n",
    "df.append(new, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete or drop or remove a column\n",
    "del df[col]\n",
    "df.drop([col1,col2], inplace=True, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
